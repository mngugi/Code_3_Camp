{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":317933,"sourceType":"datasetVersion","datasetId":133734}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n%config Completer.use_jedi = False\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T14:06:27.483417Z","iopub.execute_input":"2024-03-17T14:06:27.483841Z","iopub.status.idle":"2024-03-17T14:06:27.510094Z","shell.execute_reply.started":"2024-03-17T14:06:27.483809Z","shell.execute_reply":"2024-03-17T14:06:27.508974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House_Data = pd.read_csv(\"/kaggle/input/housing-dataset/Housing.csv\")\nHouse_Data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:31.736454Z","iopub.execute_input":"2024-03-17T14:06:31.736905Z","iopub.status.idle":"2024-03-17T14:06:31.776945Z","shell.execute_reply.started":"2024-03-17T14:06:31.736862Z","shell.execute_reply":"2024-03-17T14:06:31.775567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the length of the data frame\nHouse_Data_length = House_Data.sample(n=len(House_Data), random_state=1)\nHouse_Data_length\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:37.005439Z","iopub.execute_input":"2024-03-17T14:06:37.005859Z","iopub.status.idle":"2024-03-17T14:06:37.040125Z","shell.execute_reply.started":"2024-03-17T14:06:37.005828Z","shell.execute_reply":"2024-03-17T14:06:37.038797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House_Data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:42.440235Z","iopub.execute_input":"2024-03-17T14:06:42.440655Z","iopub.status.idle":"2024-03-17T14:06:42.449297Z","shell.execute_reply.started":"2024-03-17T14:06:42.440625Z","shell.execute_reply":"2024-03-17T14:06:42.448126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **This indicates the House dataset has 545 rows and 13 columns.**","metadata":{}},{"cell_type":"code","source":"#checking mainroad proximity\nHouse_Data['mainroad'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:47.158125Z","iopub.execute_input":"2024-03-17T14:06:47.158527Z","iopub.status.idle":"2024-03-17T14:06:47.179346Z","shell.execute_reply.started":"2024-03-17T14:06:47.158499Z","shell.execute_reply":"2024-03-17T14:06:47.177975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Convert_non_numeric = pd.get_dummies(House_Data[['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']]).astype(int)\nConvert_non_numeric","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:51.375437Z","iopub.execute_input":"2024-03-17T14:06:51.375836Z","iopub.status.idle":"2024-03-17T14:06:51.409556Z","shell.execute_reply.started":"2024-03-17T14:06:51.375806Z","shell.execute_reply":"2024-03-17T14:06:51.408217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House_Data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:06:57.801851Z","iopub.execute_input":"2024-03-17T14:06:57.802289Z","iopub.status.idle":"2024-03-17T14:06:57.837283Z","shell.execute_reply.started":"2024-03-17T14:06:57.802256Z","shell.execute_reply":"2024-03-17T14:06:57.836086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House_Data.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:01.121482Z","iopub.execute_input":"2024-03-17T14:07:01.122532Z","iopub.status.idle":"2024-03-17T14:07:01.140314Z","shell.execute_reply.started":"2024-03-17T14:07:01.122489Z","shell.execute_reply":"2024-03-17T14:07:01.138972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop non numeric variables\nHouse_Data_drop = House_Data.drop(['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea','furnishingstatus'], axis = 1)\nHouse_Data_drop","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:07.990839Z","iopub.execute_input":"2024-03-17T14:07:07.991258Z","iopub.status.idle":"2024-03-17T14:07:08.008749Z","shell.execute_reply.started":"2024-03-17T14:07:07.991227Z","shell.execute_reply":"2024-03-17T14:07:08.007645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"House_Data_Ready = pd.concat([House_Data_drop,Convert_non_numeric], axis=1)\nHouse_Data_Ready.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:12.117099Z","iopub.execute_input":"2024-03-17T14:07:12.117529Z","iopub.status.idle":"2024-03-17T14:07:12.140698Z","shell.execute_reply.started":"2024-03-17T14:07:12.117499Z","shell.execute_reply":"2024-03-17T14:07:12.139466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if there are null values after cleaning data\nHouse_Data_Ready = House_Data_Ready.dropna()\nlen(House_Data_Ready)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:16.152142Z","iopub.execute_input":"2024-03-17T14:07:16.152555Z","iopub.status.idle":"2024-03-17T14:07:16.161543Z","shell.execute_reply.started":"2024-03-17T14:07:16.152525Z","shell.execute_reply":"2024-03-17T14:07:16.160618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pd, test_pd, val_pd = House_Data_Ready[:330],House_Data_Ready[330:450],House_Data_Ready[450:]\nlen(train_pd),len(test_pd),len(val_pd)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:19.192745Z","iopub.execute_input":"2024-03-17T14:07:19.193171Z","iopub.status.idle":"2024-03-17T14:07:19.201543Z","shell.execute_reply.started":"2024-03-17T14:07:19.193140Z","shell.execute_reply":"2024-03-17T14:07:19.200281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create  a matrix\nx_train,y_train=train_pd.to_numpy()[:, :-1],train_pd.to_numpy()[:, -1]\nx_train","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:28.094138Z","iopub.execute_input":"2024-03-17T14:07:28.094571Z","iopub.status.idle":"2024-03-17T14:07:28.105279Z","shell.execute_reply.started":"2024-03-17T14:07:28.094541Z","shell.execute_reply":"2024-03-17T14:07:28.103537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:31.703809Z","iopub.execute_input":"2024-03-17T14:07:31.704240Z","iopub.status.idle":"2024-03-17T14:07:31.711141Z","shell.execute_reply.started":"2024-03-17T14:07:31.704211Z","shell.execute_reply":"2024-03-17T14:07:31.709844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:34.368877Z","iopub.execute_input":"2024-03-17T14:07:34.369299Z","iopub.status.idle":"2024-03-17T14:07:34.376810Z","shell.execute_reply.started":"2024-03-17T14:07:34.369263Z","shell.execute_reply":"2024-03-17T14:07:34.375546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setup the test model\nx_train,y_train=train_pd.to_numpy()[:, :-1],train_pd.to_numpy()[:, -1]\nx_val, y_val = val_pd.to_numpy()[:, :-1],val_pd.to_numpy()[:, -1]\nx_test, y_test = test_pd.to_numpy()[:, :-1],test_pd.to_numpy()[:, -1]\nx_train.shape, y_train.shape, x_val.shape, y_val.shape,x_test.shape, y_test.shape ","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:40.420063Z","iopub.execute_input":"2024-03-17T14:07:40.420623Z","iopub.status.idle":"2024-03-17T14:07:40.432692Z","shell.execute_reply.started":"2024-03-17T14:07:40.420585Z","shell.execute_reply":"2024-03-17T14:07:40.431068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have loaded train_pd, val_pd, test_pd from your data\n# Splitting the data as per the provided code\nx_train, y_train = train_pd.to_numpy()[:, :-1], train_pd.to_numpy()[:, -1]\nx_val, y_val = val_pd.to_numpy()[:, :-1], val_pd.to_numpy()[:, -1]\nx_test, y_test = test_pd.to_numpy()[:, :-1], test_pd.to_numpy()[:, -1]\n\n# Check the shapes\nprint(\"Training data shapes:\")\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\n\nprint(\"\\nValidation data shapes:\")\nprint(\"x_val shape:\", x_val.shape)\nprint(\"y_val shape:\", y_val.shape)\n\nprint(\"\\nTesting data shapes:\")\nprint(\"x_test shape:\", x_test.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:07:45.970936Z","iopub.execute_input":"2024-03-17T14:07:45.971364Z","iopub.status.idle":"2024-03-17T14:07:45.982788Z","shell.execute_reply.started":"2024-03-17T14:07:45.971333Z","shell.execute_reply":"2024-03-17T14:07:45.981221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Assuming x_train has 18 features\nx_train = np.random.rand(100, 18)  # Random data for example\n\n# Fit the scaler on the first 13 features\nscaler = StandardScaler().fit(x_train[:, :13])\n\ndef preprocessor(X, scaler):\n    A = np.copy(X)\n    A[:, :13] = scaler.transform(A[:, :13])\n    return A\n\n# Using the preprocessor function\nx_train_preprocessor = preprocessor(x_train, scaler)\n\n# Checking the shape of the preprocessed data\nprint(x_train_preprocessor.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:09:30.605305Z","iopub.execute_input":"2024-03-17T14:09:30.605690Z","iopub.status.idle":"2024-03-17T14:09:30.616531Z","shell.execute_reply.started":"2024-03-17T14:09:30.605661Z","shell.execute_reply":"2024-03-17T14:09:30.615380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nx_train = np.random.rand(100, 18)\n\nscaler = StandardScaler().fit(x_train[:, :13])\n\ndef preprocessor(X):\n    A = np.copy(X)\n    A[:, :13] = scaler.transform(A[:, :13])\n    return A\n\nx_train_prepropcessor = preprocessor(x_train)\nx_train_preprocessor  ","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:09:35.952023Z","iopub.execute_input":"2024-03-17T14:09:35.952420Z","iopub.status.idle":"2024-03-17T14:09:35.966976Z","shell.execute_reply.started":"2024-03-17T14:09:35.952391Z","shell.execute_reply":"2024-03-17T14:09:35.965839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(x_train_preprocessor).head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:09:41.145253Z","iopub.execute_input":"2024-03-17T14:09:41.145686Z","iopub.status.idle":"2024-03-17T14:09:41.170874Z","shell.execute_reply.started":"2024-03-17T14:09:41.145652Z","shell.execute_reply":"2024-03-17T14:09:41.169389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npd.DataFrame(x_train_preprocessor).hist()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:07:13.596973Z","iopub.execute_input":"2024-03-17T11:07:13.597450Z","iopub.status.idle":"2024-03-17T11:07:16.914923Z","shell.execute_reply.started":"2024-03-17T11:07:13.597416Z","shell.execute_reply":"2024-03-17T11:07:16.913318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(x_train_preprocessor).hist(1) # the first histogram, this can be used for all the 17 Histograms.","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:07:21.912805Z","iopub.execute_input":"2024-03-17T11:07:21.913290Z","iopub.status.idle":"2024-03-17T11:07:22.432469Z","shell.execute_reply.started":"2024-03-17T11:07:21.913255Z","shell.execute_reply":"2024-03-17T11:07:22.430878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# making models \n#sum(y_pred(x) - y)^2/n mean sqquared\n\nfrom sklearn.metrics import mean_squared_error as mse #import a mean squared error model\nfrom sklearn.linear_model import LinearRegression # import a linear regression\n\nlin_R = LinearRegression().fit(x_train, y_train) # fit in the train model into linearregression model\nmse(lin_R.predict(x_train), y_train)        # find the mse of the predicted attributes        \n\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-22T17:40:17.707955Z","iopub.execute_input":"2024-03-22T17:40:17.708804Z","iopub.status.idle":"2024-03-22T17:40:17.716220Z","shell.execute_reply.started":"2024-03-22T17:40:17.708771Z","shell.execute_reply":"2024-03-22T17:40:17.715157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n'''from sklearn.metrics import mean_squared_error as mse\nfrom sklearn.linear_model import LinearRegression\n\n# Assuming x_train and y_train are correctly defined as per the previous steps\n\nlin_R = LinearRegression().fit(x_train, y_train)\nmse_train = mse(lin_R.predict(x_train), y_train)\nprint(\"MSE on training data:\", mse_train)\n\n# If you have validation data, you can calculate MSE on validation data as well\nmse_val = mse(lin_R.predict(x_val), y_val)\nprint(\"MSE on validation data:\", mse_val)\n\n# If you have test data, you can calculate MSE on test data as well\nmse_test = mse(lin_R.predict(x_test), y_test)\nprint(\"MSE on test data:\", mse_test)\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-22T17:40:17.718218Z","iopub.execute_input":"2024-03-22T17:40:17.718550Z","iopub.status.idle":"2024-03-22T17:40:17.728453Z","shell.execute_reply.started":"2024-03-22T17:40:17.718523Z","shell.execute_reply":"2024-03-22T17:40:17.727093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data\nx_train, y_train = train_pd.iloc[:, :-1].values, train_pd.iloc[:, -1].values\nx_val, y_val = val_pd.iloc[:, :-1].values, val_pd.iloc[:, -1].values\nx_test, y_test = test_pd.iloc[:, :-1].values, test_pd.iloc[:, -1].values\n\n# Check the shapes\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"x_val shape:\", x_val.shape)\nprint(\"y_val shape:\", y_val.shape)\nprint(\"x_test shape:\", x_test.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:16.704365Z","iopub.execute_input":"2024-03-17T14:10:16.704834Z","iopub.status.idle":"2024-03-17T14:10:16.715259Z","shell.execute_reply.started":"2024-03-17T14:10:16.704755Z","shell.execute_reply":"2024-03-17T14:10:16.713958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Sample DataFrames (assuming they have the same number of rows)\ntrain_pd = pd.DataFrame({\n    'feature1': np.random.randn(100),\n    'feature2': np.random.randn(100),\n    'target': np.random.randn(100)\n})\n\nval_pd = pd.DataFrame({\n    'feature1': np.random.randn(30),\n    'feature2': np.random.randn(30),\n    'target': np.random.randn(30)\n})\n\ntest_pd = pd.DataFrame({\n    'feature1': np.random.randn(50),\n    'feature2': np.random.randn(50),\n    'target': np.random.randn(50)\n})\n\n# Splitting the data\nx_train, y_train = train_pd.iloc[:, :-1].values, train_pd.iloc[:, -1].values\nx_val, y_val = val_pd.iloc[:, :-1].values, val_pd.iloc[:, -1].values\nx_test, y_test = test_pd.iloc[:, :-1].values, test_pd.iloc[:, -1].values\n\n# Check the shapes\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"x_val shape:\", x_val.shape)\nprint(\"y_val shape:\", y_val.shape)\nprint(\"x_test shape:\", x_test.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:34.896936Z","iopub.execute_input":"2024-03-17T14:10:34.897398Z","iopub.status.idle":"2024-03-17T14:10:34.912477Z","shell.execute_reply.started":"2024-03-17T14:10:34.897363Z","shell.execute_reply":"2024-03-17T14:10:34.911188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making models \n#sum(y_pred(x) - y)^2/n mean sqquared\n\nfrom sklearn.metrics import mean_squared_error as mse #import a mean squared error model\nfrom sklearn.linear_model import LinearRegression # import a linear regression\n\nlin_R = LinearRegression().fit(x_train, y_train) # fit in the train model into linearregression model\nmse_xtrain = mse(lin_R.predict(x_train), y_train, squared=False)\nmse_yval = mse(lin_R.predict(x_val), y_val, squared=False)         # find the mse of the predicted attributes   \n\nprint(\"Mse for X Train is: \", mse_xtrain)\nprint(\"Mse for y val is: \", mse_yval)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:50.205571Z","iopub.execute_input":"2024-03-17T14:10:50.206053Z","iopub.status.idle":"2024-03-17T14:10:50.237080Z","shell.execute_reply.started":"2024-03-17T14:10:50.206018Z","shell.execute_reply":"2024-03-17T14:10:50.235904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knn model \nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error as mse\nknn = KNeighborsRegressor(n_neighbors=15).fit(x_train, y_train)  # here i used a fit for 15 to make it closer to the validation\nknn_xtrain = mse(knn.predict(x_train), y_train, squared=False)\nknn_xval = mse(knn.predict(x_val), y_val, squared=False) \n\nprint(\"KNN xtrain is :\", knn_xtrain)\nprint(\"KNN validation is: \", knn_xval)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:54.149222Z","iopub.execute_input":"2024-03-17T14:10:54.149800Z","iopub.status.idle":"2024-03-17T14:10:54.231206Z","shell.execute_reply.started":"2024-03-17T14:10:54.149751Z","shell.execute_reply":"2024-03-17T14:10:54.229706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nran_forest = RandomForestRegressor(max_depth=1).fit(x_train, y_train)\n\nranForest_xtrain = mse(ran_forest.predict(x_train), y_train, squared=False)\nranForest = mse(ran_forest.predict(x_val), y_val, squared=False) \n\nprint(\"Random forest xtrain is :\", ranForest_xtrain)\nprint(\"Random forest validation is: \", ranForest)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:57.690132Z","iopub.execute_input":"2024-03-17T14:10:57.690577Z","iopub.status.idle":"2024-03-17T14:10:58.014125Z","shell.execute_reply.started":"2024-03-17T14:10:57.690546Z","shell.execute_reply":"2024-03-17T14:10:58.012941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor(n_estimators=1).fit(x_train, y_train)\n\ngbr_xtrain = mse(gbr.predict(x_train), y_train, squared=False)\ngbr_val = mse(gbr.predict(x_val), y_val, squared=False)\n\nprint(\"The Gradient Boosting Regressor for Xtrain is:\", gbr_xtrain)\nprint(\"The Gradient Boosting Regressor for Val is:\", gbr_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:11:02.155188Z","iopub.execute_input":"2024-03-17T14:11:02.156427Z","iopub.status.idle":"2024-03-17T14:11:02.173709Z","shell.execute_reply.started":"2024-03-17T14:11:02.156370Z","shell.execute_reply":"2024-03-17T14:11:02.172162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data)\n\n# Convert 'furnishingstatus' to one-hot encoding\ndf_encoded = pd.get_dummies(df, columns=['furnishingstatus'])\n\n# Separate features (x) and target (y)\nx = df_encoded.drop('price', axis=1)\ny = df_encoded['price']\n\n# Convert target 'y' to float32\ny = y.astype('float32')\n\nprint(y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Convert y_train and y_val to float32\ny_train = y_train.astype(np.float32)\ny_val = y_val.astype(np.float32)\n\n# Now train the model\nstart_nn.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[cp], epochs=100)\n'''\n# Define the model with explicit Input layer\nstart_nn = Sequential([\n    Input(shape=(2,)),  # Assuming input data has shape (None, 2)\n    Dense(64, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(1, activation='linear')\n])\n\n# Compile with appropriate filepath for ModelCheckpoint\nopt = Adam()\ncp = ModelCheckpoint('model/start_nn.keras', save_best_only=True)\nstart_nn.compile(optimizer=opt, loss='mse', metrics=['RootMeanSquaredError'])\n\n# Fit the model with specified callbacks\nstart_nn.fit(x_train, y_train, validation_data=(x_val, y_val),\n             callbacks=[cp], epochs=100)\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:41:42.504352Z","iopub.execute_input":"2024-03-17T14:41:42.504768Z","iopub.status.idle":"2024-03-17T14:41:43.914494Z","shell.execute_reply.started":"2024-03-17T14:41:42.504738Z","shell.execute_reply":"2024-03-17T14:41:43.912918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as mse\n\n# Sample data\ntrain_data = {\n    'feature1': [1, 2, 3, 4],\n    'feature2': [4, 3, 2, 1],\n    'target': ['furnished', 'unfurnished', 'furnished', 'unfurnished']\n}\n\n# Convert to DataFrame\ntrain_pd = pd.DataFrame(train_data)\n\n# Split features and target\nx_train = train_pd[['feature1', 'feature2']].to_numpy()\ny_train = train_pd['target']\n\n# One-hot encode the target\ny_train_encoded = pd.get_dummies(y_train)['furnished']\n\n# Train the model\nlin_R = LinearRegression().fit(x_train, y_train_encoded)\nmse_value = mse(lin_R.predict(x_train), y_train_encoded)\nprint(\"Mean Squared Error:\", mse_value)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:18:57.477841Z","iopub.execute_input":"2024-03-17T14:18:57.478279Z","iopub.status.idle":"2024-03-17T14:18:57.495180Z","shell.execute_reply.started":"2024-03-17T14:18:57.478242Z","shell.execute_reply":"2024-03-17T14:18:57.493970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Calculate Mean Squared Error (MSE) and Mean Absolute Error (MAE) for training data\nY_pred_train = model.predict(X_train)\nmse_train = mean_squared_error(Y_train, Y_pred_train)\nmae_train = mean_absolute_error(Y_train, Y_pred_train)\nprint(\"Training MSE:\", mse_train)\nprint(\"Training MAE:\", mae_train)\n\n# Calculate Mean Squared Error (MSE) and Mean Absolute Error (MAE) for testing data\nmse_test = mean_squared_error(Y_test, Y_pred)\nmae_test = mean_absolute_error(Y_test, Y_pred)\nprint(\"Testing MSE:\", mse_test)\nprint(\"Testing MAE:\", mae_test)\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the data from the CSV file\nHouse_Data = pd.read_csv(\"/kaggle/input/housing-dataset/Housing.csv\")\n\n# Map 'yes' and 'no' to boolean values\nboolean_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\nHouse_Data[boolean_columns] = House_Data[boolean_columns].replace({'yes': True, 'no': False})\n\n# Display the first few rows of the cleaned DataFrame\nhdt = House_Data\nhdt.head()\n#print(House_Data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:18:38.872558Z","iopub.execute_input":"2024-03-17T14:18:38.873118Z","iopub.status.idle":"2024-03-17T14:18:38.911411Z","shell.execute_reply.started":"2024-03-17T14:18:38.873076Z","shell.execute_reply":"2024-03-17T14:18:38.910280Z"},"trusted":true},"execution_count":null,"outputs":[]}]}